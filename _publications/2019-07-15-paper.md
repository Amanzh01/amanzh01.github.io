---
title: "Myers-Briggs Personality Classification and Personality-Specific Language Generation Using Pre-trained Language Models"
collection: publications
permalink: /publication/2019-07-15-paper
excerpt: ''
date: 2019-07-15
venue: 'ArXiV'
paperurl: 'https://arxiv.org/pdf/1907.06333.pdf'
authors: 'Sedrick Scott Keh, I-Tsun Cheng'
citation: 'Keh, S. S., & Cheng, I. C. (2019, July). Myers-Briggs Personality Classification and Personality-Specific Language Generation Using Pre-trained Language Models. ArXiv.'
paper: 'https://arxiv.org/pdf/1907.06333.pdf'
abstract: 'The Myers-Briggs Type Indicator (MBTI) is a popular personality metric that uses four dichotomies as indicators of personality traits. This paper examines the use of pre-trained language models to predict MBTI personality types based on scraped labeled texts. The proposed model reaches an accuracy of 0.47 for correctly predicting all 4 types and 0.86 for correctly predicting at least 2 types. Furthermore, we investigate the possible uses of a fine-tuned BERT model for personality-specific language generation. This is a task essential for both modern psychology and for intelligent empathetic systems.'
---

[Paper](https://arxiv.org/pdf/1907.06333.pdf)

Recommended citation: Keh, S. S., & Cheng, I. C. (2019, July). Myers-Briggs Personality Classification and Personality-Specific Language Generation Using Pre-trained Language Models. ArXiv